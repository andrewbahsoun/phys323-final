{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22627613-c3a1-400e-a210-56a271833be7",
   "metadata": {},
   "source": [
    "## image classification using tensorflow for handwashing    \n",
    "### methodology:\n",
    "- seperate into train and test data\n",
    "- seperate into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "807a1d05-d011-46be-ac87-7aabfa6eb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc051070",
   "metadata": {},
   "source": [
    "``input_dir`` contains the video files    \n",
    "``output_frames_dir_test`` will contain 30% of the frames         \n",
    "``output_frames_dir_train`` will contain the other 70% of the frames        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "49067f38-5749-488a-a97a-16ecbe888f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Users/andrewbahsoun/Documents/computer_science/sci-250/hand-washing/data/HandWashDataset/'\n",
    "output_frames_dir_test = '/Users/andrewbahsoun/Documents/computer_science/sci-250/hand-washing/data/outputFrames/test'\n",
    "output_frames_dir_train = '/Users/andrewbahsoun/Documents/computer_science/sci-250/hand-washing/data/outputFrames/train'\n",
    "\n",
    "steps = ['nostep0', 'Step_1', 'Step_2', 'Step_3', 'Step_4', 'Step_5', 'Step_6', 'Step_7', 'Step_8', 'Step_9', 'Step_10', 'Step_11', 'Step_12' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cb736",
   "metadata": {},
   "source": [
    "Creates a dictonary with 12 classes, the key is the step number, the value is a list with the path of all the videos that will enter the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "165017cd-515f-46a7-9e88-ae704df3322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_names_dict = {\n",
    "    1: [],\n",
    "    2: [],\n",
    "    3: [],\n",
    "    4: [],\n",
    "    5: [],\n",
    "    6: [],\n",
    "    7: [],\n",
    "    8: [],\n",
    "    9: [],\n",
    "    10: [],\n",
    "    11: [],\n",
    "    12: []\n",
    "}\n",
    "\n",
    "\n",
    "for step in range(1, 13):\n",
    "    \n",
    "    for name in os.listdir(os.path.join(input_dir, steps[step])):\n",
    "        # Open file\n",
    "        with open(os.path.join(input_dir, steps[step], name)) as f:\n",
    "            all_file_names_dict[step].append(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8c443-ab0c-4157-8445-53ab989d119c",
   "metadata": {},
   "source": [
    "### get all videos into frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28cc97c0-c82d-4db7-8dc0-6803743b7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function reads a video file, extracts each frame, and saves the frames as JPEG images in the specified output directory. \n",
    "It uses OpenCV to read the video, processes frames sequentially, and assigns filenames based on the frame number and the original video filename. \n",
    "The process continues until all frames are saved.\n",
    "'''\n",
    "def get_frames_from_video(directory, filename, step, output_frames_dir):\n",
    "    # Creating a VideoCapture object to read the video\n",
    "    cap = cv2.VideoCapture(os.path.join(directory, steps[step], filename))\n",
    "\n",
    "    is_success, image = cap.read()\n",
    "    frame_number = 0\n",
    "\n",
    "    while is_success:\n",
    "        out_filename = \"frame_{}_{}.jpg\".format(frame_number, os.path.splitext(filename)[0])\n",
    "        save_path_and_name = os.path.join(output_frames_dir, out_filename)\n",
    "        cv2.imwrite(save_path_and_name, image)\n",
    "        is_success, image = cap.read()\n",
    "        frame_number += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197706d",
   "metadata": {},
   "source": [
    "This code splits videos from each step into training and testing datasets based on a `test_ratio` of 30% for testing. It processes each video, skips the system files `.DS_Store`, and extracts frames using `get_frames_from_video`, saving them in the appropriate output directories. The `counter` ensures videos are distributed correctly between training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6a3e94f7-e157-48c0-a23c-1750ddd0715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "for step in range(1,13):\n",
    "    counter = 0\n",
    "    for video in all_file_names_dict[step]:\n",
    "        if (video != \".DS_Store\"):\n",
    "\n",
    "            if ((len(all_file_names_dict) * (1-test_ratio) ) < counter):\n",
    "                #train data\n",
    "                get_frames_from_video(input_dir, video, step, output_frames_dir_train)\n",
    "            else:\n",
    "                #test data\n",
    "                get_frames_from_video(input_dir, video, step, output_frames_dir_test)\n",
    "            counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653cdd2-8b71-4dac-beda-c603771728e5",
   "metadata": {},
   "source": [
    "#### debugging purposes \n",
    "this will print out all the files in the directory onto a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c44b1941-96d0-4d81-983f-e74aaf54e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_of_videos_per_step(directory, output_filename):\n",
    "    with open(output_filename, 'a') as f:  # Open the file in append mode\n",
    "        for name in os.listdir(directory):\n",
    "            f.write(name + '\\n')  # Write each name on a new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b768e7-1119-494f-ab9f-adf229e5a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_num_of_videos_per_step(output_frames_dir_test, 'test_videos')\n",
    "find_num_of_videos_per_step(output_frames_dir_train, 'train_videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec85b2c-bce1-4e83-b716-444f0f547a84",
   "metadata": {},
   "source": [
    "### get photos into directories by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "589b6d57-bd26-4291-95de-c54cb0315661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_video_into_subdirectory_onedigit(directory, output_dir, step):\n",
    "    for name in os.listdir(directory):\n",
    "            if (\"A_0\" + str(step)) in name:\n",
    "                shutil.move(os.path.join(directory, name), output_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73d52e42-50b5-473e-a148-f6a95df50202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_video_into_subdirectory_twodigit(directory, output_dir, step):\n",
    "    for name in os.listdir(directory):\n",
    "            if (\"A_\" + str(step)) in name:\n",
    "                shutil.move(os.path.join(directory, name), output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5fc211b-773c-4d33-be4c-79f924088f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving all test photos step(1-9) into their respective directories\n",
    "for step in range(1, 10):\n",
    "    move_video_into_subdirectory_onedigit(output_frames_dir_test, os.path.join(output_frames_dir_test,('step_' + str(step))), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "265c11ee-b47f-41c1-b118-4ae4f2550ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving all test photos step(10-12) into their respective directories\n",
    "for step in range(10, 13):\n",
    "    move_video_into_subdirectory_twodigit(output_frames_dir_test, os.path.join(output_frames_dir_test,('step_' + str(step))), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cb66b51-0839-4569-8939-b2c4c5fee8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving all train photos step(1-9) into their respective directories\n",
    "for step in range(1, 10):\n",
    "    move_video_into_subdirectory_onedigit(output_frames_dir_train, os.path.join(output_frames_dir_train,('step_' + str(step))), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5327dae1-1f57-48c0-8726-c5db35e5e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving all train photos step(10-12) into their respective directories\n",
    "for step in range(10, 13):\n",
    "    move_video_into_subdirectory_twodigit(output_frames_dir_train, os.path.join(output_frames_dir_train,('step_' + str(step))), step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
